{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RJAPoaNttEy"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv\n",
        "!pip install pytest-playwright\n",
        "!playwright install\n",
        "!pip install nest_asyncio\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrNgUHbPtvXc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup, Comment, SoupStrainer\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import boto3\n",
        "import uuid\n",
        "import argparse\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TOYRrE1u_Lf"
      },
      "outputs": [],
      "source": [
        "def filter_source(source):\n",
        "  soup = BeautifulSoup(source, 'html.parser')\n",
        "  body_content = soup.body.decode_contents()\n",
        "\n",
        "  for script in soup([\"script\", \"style\", \"img\", \"nav\", \"header\", \"footer\", \"picture\", \"svg\", \"path\", \"form\"]):\n",
        "      script.decompose()\n",
        "\n",
        "  cleaned_body_content = str(soup.body)\n",
        "  return cleaned_body_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJUC_A5Gt4Sv"
      },
      "outputs": [],
      "source": [
        "#global variable\n",
        "review_paginate_next = \"\"\n",
        "review_author = \"\"\n",
        "review_title = \"\"\n",
        "review_text = \"\"\n",
        "review_rating = \"\"\n",
        "\n",
        "prompt = \"\"\"extract the following class name for each of the following elements:\n",
        "- pagination \"next page\" button of review section\n",
        "- name of reviewer\n",
        "- title of review\n",
        "- text of review\n",
        "- rating classname\n",
        "from the provided codebase.\n",
        "Just return a comma seperated value of classnames, if multiple class name is found for the same section, use the most relevant one which is unique.\n",
        "Don't trim the values, return the value as it is in source code.\n",
        "Don't return any other text than mentioned. Here is the code: \"\"\"\n",
        "\n",
        "def filter_css_selector(source_text, max_retries = 3):\n",
        "    google_api_key = os.getenv('GOOGLE_API_KEY')\n",
        "    response = requests.post(\n",
        "        url=f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={google_api_key}\",\n",
        "        headers={\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"contents\": [\n",
        "                {\n",
        "                    \"parts\": [\n",
        "                        {\n",
        "                            \"text\": prompt + source_text\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        message_content = data['candidates'][0]['content']['parts'][0]['text']\n",
        "        message_content = message_content.strip(\"\\n\")\n",
        "        try:\n",
        "          global review_paginate_next, review_author, review_title, review_text, review_rating\n",
        "          review_paginate_next, review_author, review_title, review_text, review_rating = message_content.split(\",\")\n",
        "          next_buttons.append(f'.{review_paginate_next}')\n",
        "          print(review_paginate_next)\n",
        "          print(review_author)\n",
        "          print(review_title)\n",
        "          print(review_text)\n",
        "          print(review_rating)\n",
        "\n",
        "        except:\n",
        "          # also try with some other model\n",
        "          if (max_retries > 0):\n",
        "            time.sleep(2)\n",
        "            filter_css_selector(source_text, max_retries - 1)\n",
        "    else:\n",
        "        # handles model overload error or any other error encountered by LLM API\n",
        "        print(response.json())\n",
        "        if (max_retries > 0):\n",
        "          time.sleep(2)\n",
        "          filter_css_selector(source_text, max_retries - 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28V1zCF7AolG"
      },
      "outputs": [],
      "source": [
        "fallback_reviews = dict()\n",
        "fallback_prompt = \"\"\"extract the reviews from the given source code in json object in the format {\n",
        "  \"reviews_count\": 100,\n",
        "  \"reviews\": [\n",
        "    {\n",
        "      \"title\": \"Review Title\",\n",
        "      \"body\": \"Review body text\",\n",
        "      \"rating\": 5,\n",
        "      \"reviewer\": \"Reviewer Name\"\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "}.\n",
        "Don't add any code formating.\n",
        "Here is the source code: \"\"\"\n",
        "\n",
        "def fallback_review_extraction(source_text, max_retries = 3):\n",
        "    google_api_key = os.getenv('GOOGLE_API_KEY')\n",
        "    response = requests.post(\n",
        "        url=f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={google_api_key}\",\n",
        "        headers={\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"contents\": [\n",
        "                {\n",
        "                    \"parts\": [\n",
        "                        {\n",
        "                            \"text\": fallback_prompt + source_text\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        message_content = data['candidates'][0]['content']['parts'][0]['text']\n",
        "        message_content = message_content.strip(\"\\n\")\n",
        "        global fallback_reviews\n",
        "        fallback_reviews = json.loads(message_content)\n",
        "        print(fallback_reviews)\n",
        "\n",
        "    else:\n",
        "        # handles model overload error or any other error encountered by LLM API\n",
        "        print(response.json())\n",
        "        if (max_retries > 0):\n",
        "          time.sleep(2)\n",
        "          fallback_review_extraction(source_text, max_retries - 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai3IHLVQSJxk"
      },
      "outputs": [],
      "source": [
        "def extract_reviews(source):\n",
        "\n",
        "  body_strainer = SoupStrainer('body')\n",
        "  soup = BeautifulSoup(source, 'html.parser', parse_only=body_strainer)\n",
        "\n",
        "  titles = soup.find_all(class_=review_title)\n",
        "  bodies = soup.find_all(class_=review_text)\n",
        "  authors = soup.find_all(class_=review_author)\n",
        "  ratings = soup.find_all(class_=review_rating)\n",
        "\n",
        "\n",
        "  for i in range(max(len(titles), len(bodies), len(authors), len(ratings))):\n",
        "      review = {\n",
        "          \"title\": titles[i].get_text(strip=True) if i < len(titles) else \"\",\n",
        "          \"body\": bodies[i].get_text(strip=True) if i < len(bodies) else \"\",\n",
        "          \"author\": authors[i].get_text(strip=True) if i < len(authors) else \"\",\n",
        "          \"rating\": ratings[i].get_text(strip=True) if i < len(ratings) else \"\"\n",
        "      }\n",
        "      reviews.append(review)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm5PswySe_pu"
      },
      "outputs": [],
      "source": [
        "dialog_prompt = \"\"\"extract the classname of popup close button.\n",
        "Just return a single word containing the classname.\n",
        "Don't add any code formating.\n",
        "Here is the source code: \"\"\"\n",
        "\n",
        "def get_dialog_close_button(source_text, max_retries = 2):\n",
        "    google_api_key = 'AIzaSyCDSeoTj9yTAQTm-SDdj3XIyu3ir7lcj_k'\n",
        "    response = requests.post(\n",
        "        url=f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={google_api_key}\",\n",
        "        headers={\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"contents\": [\n",
        "                {\n",
        "                    \"parts\": [\n",
        "                        {\n",
        "                            \"text\": dialog_prompt + source_text\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        message_content = data['candidates'][0]['content']['parts'][0]['text']\n",
        "        message_content = message_content.strip(\"\\n\")\n",
        "        return message_content\n",
        "    else:\n",
        "        # handles model overload error or any other error encountered by LLM API\n",
        "        print(response.json())\n",
        "        if (max_retries > 0):\n",
        "          time.sleep(2)\n",
        "          get_dialog_close_button(source_text, max_retries - 1)\n",
        "        return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xsCpy9N-ceQ"
      },
      "outputs": [],
      "source": [
        "def upload_to_s3(data, unique_file_name):\n",
        "    s3_client = boto3.client('s3')  # Create an S3 client\n",
        "\n",
        "    bucket_name = 'extracted-reviews'  # Replace with your bucket name\n",
        "\n",
        "    s3_client.put_object(\n",
        "        Bucket=bucket_name,\n",
        "        Key=unique_file_name,\n",
        "        Body=json.dumps(data),  # Convert list to JSON string\n",
        "        ContentType='application/json'\n",
        "    )\n",
        "\n",
        "    print(f\"Responses uploaded to s3://{bucket_name}/{unique_file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq0ZI2LFt8VN"
      },
      "outputs": [],
      "source": [
        "# url = \"https://2717recovery.com/products/recovery-cream\"\n",
        "# url = \"https://www.trustpilot.com\"\n",
        "# url = \"https://milky-mama.com/pages/customer-reviews\"\n",
        "# url = \"https://lyfefuel.com/products/essentials-nutrition-shake\"\n",
        "# url = \"https://www.allbirds.com/products/mens-tree-dashers-twilight-white-twilight-teal?price-tiers=msrp%2Ctier-1%2Ctier-2\"\n",
        "# url = \"https://www.shopclues.com/chamria-hing-wati-digestive-mouth-freshner-200-gm-can-pack-of-2-153514795.html\"\n",
        "nest_asyncio.apply()\n",
        "responses_list = {}\n",
        "reviews = []\n",
        "next_buttons = ['a[aria-label=\"Goto next page\"]']\n",
        "dialog_close_buttons = ['.store-selection-popup--close']\n",
        "\n",
        "async def scrape(url, file_name):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "        await page.goto(url)\n",
        "\n",
        "        await page.wait_for_selector('body')\n",
        "        page_source = await page.content()\n",
        "\n",
        "        cleaned_body_content = filter_source(page_source)\n",
        "        filter_css_selector(cleaned_body_content)\n",
        "        # time.sleep(5)\n",
        "\n",
        "        # Perform all three operation on pagination, click read more, load more etc button. Scroll to the bottom of page.\n",
        "\n",
        "        # pagination_type = determine_pagination_type(page_source)\n",
        "\n",
        "        dialog_close_attempt = 1\n",
        "        for elm in next_buttons:\n",
        "          count = 0\n",
        "          while True:\n",
        "              await page.wait_for_selector('body')\n",
        "              page_source = await page.content()\n",
        "\n",
        "              extract_reviews(page_source)\n",
        "\n",
        "              print(count)\n",
        "              count += 1\n",
        "              if (count > 20): break\n",
        "\n",
        "              try:\n",
        "                  next_button = page.locator(elm)\n",
        "\n",
        "                  await page.mouse.click(x=0, y=page.viewport_size['height'] // 2)\n",
        "\n",
        "                  await asyncio.wait_for(next_button.click(), timeout=5)\n",
        "\n",
        "                  # Wait for the next page to load and for specific element to be visible\n",
        "                  await page.wait_for_load_state('networkidle')\n",
        "                  await page.wait_for_selector('body')\n",
        "\n",
        "              except asyncio.TimeoutError:\n",
        "                  # print(\"Timeout occurred while waiting for the next page. Stopping the process.\")\n",
        "                  # if (dialog_close_attempt > 0 and count < 2):\n",
        "                  #   dialog_close_attempt -= 1\n",
        "                  #   await page.mouse.click(x=0, y=page.viewport_size['height'] // 2)\n",
        "                  #   cleaned_source = filter_source(page_source)\n",
        "                  #   dialog_close_button_class = get_dialog_close_button(cleaned_source)\n",
        "                  #   dialog_close_buttons.append(f'.{dialog_close_button_class}')\n",
        "                  #   for elm in dialog_close_buttons:\n",
        "                  #     print(elm)\n",
        "                  #     if dialog_close_button_class:\n",
        "                  #       dialog_close_button = page.locator(elm)\n",
        "                  #       try:\n",
        "                  #         await asyncio.wait_for(dialog_close_button.click(), timeout=3)\n",
        "                  #         break\n",
        "                  #       except:\n",
        "                  #         continue\n",
        "                  # else:\n",
        "                  #   break  # Break the loop if it takes too long to change pages\n",
        "                  break\n",
        "              except Exception as e:\n",
        "                print(\"Bro, error with pagination? \", e)\n",
        "                break\n",
        "\n",
        "        #Handle infinite scroll\n",
        "        prev_height = -1\n",
        "        max_scrolls = 5  # Set a maximum number of scrolls to prevent infinite loops\n",
        "        scroll_count = 0\n",
        "\n",
        "        while scroll_count < max_scrolls:\n",
        "            await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
        "            await page.wait_for_timeout(200)\n",
        "            new_height = await page.evaluate(\"document.body.scrollHeight\")\n",
        "\n",
        "            if new_height == prev_height:\n",
        "                break\n",
        "\n",
        "            prev_height = new_height\n",
        "            scroll_count += 1\n",
        "\n",
        "        page_source = await page.content()\n",
        "        extract_reviews(page_source)\n",
        "        #Handle infinite scroll end\n",
        "\n",
        "        # print(len(reviews))\n",
        "        # print(reviews)\n",
        "\n",
        "        if (len(reviews) == 0):\n",
        "          fallback_review_extraction(cleaned_body_content)\n",
        "          fallback_reviews[\"reviews_count\"] = len(fallback_reviews[\"reviews\"])\n",
        "          # upload_to_s3(fallback_reviews, file_name)\n",
        "          print(fallback_reviews)\n",
        "        else:\n",
        "          reviews_dict = {\"reviews_count\" : len(reviews), \"reviews\": reviews}\n",
        "          print(reviews_dict)\n",
        "          # upload_to_s3(reviews_dict, file_name)\n",
        "\n",
        "asyncio.run(scrape(\"https://2717recovery.com/products/recovery-cream\", \"uuid.json\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3eRMkkqA9JO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
